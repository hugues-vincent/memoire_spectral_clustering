% \part{partie}
% \chapter{chapitre}
% \section{section}
% \subsection{sous-section}
% \subsubsection{sous-sous-section}
% \paragraph{paragraphe}
% \subparagraph{sous-paragraphe}
\section{Théorie}
\subsection{Contexte: Stochastic Block Model à 2 communautés}
Le but de ce papier est d'expliquer en détail la méthode de détection de communauté via la théorie spectrale de l'article de RR. Nadakuditi et M. E. J. Newmann.
C'est un article qui décrit les limites d'un modèle spectral dans un cadre spécifique à deux communautés.

Nous allons nous placer dans le contexte d'un Stochastic Block Model (SBM) à deux communautés (i.e \textbf{q}=2).
Autrement dit, dans un graphe \textbf{G} non orienté à \textbf{n} noeuds dont la probabilité d'existence d'une arête entre deux noeuds est la suivante:
\begin{itemize}\label{rq:probability}
    \item[Même communauté:] $\mathbf{p_{in}}$  
    \item[Différentes communautés:] $\mathbf{p_{out}}$\\
\end{itemize}

Nous noterons \textbf{A} la matrice d'adjacence du graphe \textbf{G}.
Elle est symétrique de par le fait que le graphe soit non orienté.
Nous supposerons d'ailleurs, que ses éléments sont rangés dans l'ordre de leur communauté.
Dans notre cas avec \textbf{q}=2, les $\mathbf{n}/2$ premières lignes correspondent aux noeuds de la communauté 1, et les $\mathbf{n}/2$ dernières la communauté 2.
Même chose pour les colonnes, par symétrie de \textbf{A}.
Chaque élément de la matrice \textbf{A} est simulé par une loi de Bernoulli avec: 
\begin{equation} 
 A_{ij} \sim \left\{
  \begin{array}{lr}
    B(p_{in}) & : (i,j < \frac{n}{2}) \lor (i,j \ge \frac{n}{2}) \\
    B(p_{out}) & : else \; where
  \end{array}
\right.\nonumber
\end{equation}
\begin{equation} 
A_{ij} = A_{ji}\nonumber
\end{equation}


\subsection{Analyse spectrale de la matrice d'adjacence \textbf{A}}\label{ch:Analyse spectrale de la matrice d'adjacence}
L'idée générale de l'analyse spectrale qui va suivre est de nous ramener à un régime spectral de grande matrices aléatoires connu. 
Dans notre cas, nous verrons que le régime associé à notre matrice d'adjacence (SBM $\textbf{q}=2$) est celui du théorème de \textit{Wigner} avec perturbations de rang 1.
La trame sera la suivante:
\begin{itemize}
 	\item[1-] réécriture de la matrice $A = \langle A \rangle + X$;
 	\item[2-] étude de la mesure spectrale de X;
 	\item[3-] étude de la mesure spectrale de B tel que $B = X + P1$;
 	\item[4-] étude de la mesure spectrale de $A = B + P2 = X + P1 + P2$.
 \end{itemize} 
où $P1$, $P2$ sont des perturbations de rang 1 et $\langle A \rangle$ correspond à la moyenne de A du SBM.\\

Soit
% ------------------------------------------------- equation (1) -------------------------------------------------
\begin{equation} 
\langle A \rangle := \frac{1}{2}(c_{in} + c_{out})\mathbf{11}^T + \frac{1}{2}(c_{in} - c_{out})\mathbf{uu}^T \label{eq:1}
\end{equation}
Avec
\begin{align*}
c_{in} &= np_{int} \\
c_{out} &= np_{out}\\
\mathbf{1} &= (1, 1, \ldots)/\sqrt{n}\\
\mathbf{u} &= (1, 1, \ldots, -1, -1, \ldots)/\sqrt{n}
\end{align*}

À présent \textbf{A} peut être écrite sous la forme $A = \langle A \rangle + X$.
X est interprétable comme la déviation entre la matrice d'adjacence du graphe et sa moyenne.
X est par définition une matrice aléatoire symétrique à entrées indépendantes et de moyenne 0.
Essayons d'analyser sa mesure spectrale.
On a 

\begin{equation}
X = A - \langle A \rangle\nonumber
\end{equation}
\begin{equation}
	X_{ij} \sim \left\{
	\begin{array}{lr}
		B(p_{in}) - p_{in} & : (i,j < \frac{n}{2}) \lor (i,j \ge \frac{n}{2}) \\
		B(p_{out}) - p_{out} & : else \; where
	\end{array}
\right.\nonumber
\end{equation}

% ------------------------------------------------- réécriture de X_ij -------------------------------------------------
Nous aimerions modifier la forme des entrées $X_{ij}$ en $\sigma_{ij} Z_{ij}$, où $Z_{ij}$ est une variable aléatoire centrée réduite, afin de nous ramener à des théorèmes connus.

Pour $(i,j < \frac{n}{2}) \lor (i,j \ge \frac{n}{2}) $ on a:
\begin{align*}
\mathbb{E}(X_{ij}) &= \mathbb{E}(B(p_{in}))- p_{in} = 0\\
\sigma_{in}^2 &= \mathbb{V}(X_{ij}) \\ 
			  &= \mathbb{V}(B(p_{in})) \\
			  &= p_{in} (1 - p_{in})
\end{align*}
même raisonnement avec $p_{out}$ 
\begin{align*}
\sigma_{out}^2 =  p_{out} (1 - p_{out})
\end{align*}
finalement on obtient 
\begin{equation}
	X_{ij} \sim \left\{
	\begin{array}{lr}
		\sigma_{in} Z_{ij} & : (i,j < \frac{n}{2}) \lor (i,j \ge \frac{n}{2}) \\
		\sigma_{out} Z_{ij} & : else \; where
	\end{array}
\right.\nonumber
\end{equation}
Où $Z_{ij} = \frac{B(p) - p}{\sqrt{p(1-p)}} \;\;avec \; p = p_{in} \lor p_{out}$\\

% ------------------------------------------------- théorème 1 -------------------------------------------------
Le théorème de Wigner ne fonctionne que pour les matrices à entrées iid, or l'écart type est dépendant des indices de la matrice.
Cependant il existe un théorème pour notre cas.
\begin{theorem}\label{th:1}
Soit $W \in M_{n}(\mathbb{R})$, $W_{ij}$ sont des variables aléatoires réels, $\mathbb{E}(W_{ij}) = 0$, $\mathbb{E}(W_{ij}^2) < \infty$, $W_{ij} = W_{ji}$

Si le profil de variance de $\frac{W}{\sqrt{n}}$, $V$, est telle que $\forall i = 1:n , \; \sum_{j=1}^{n}V_{ij} = \sigma^2$ pour $\sigma \in \mathbb{R}$

Alors si on note la mesure spectrale de $\frac{W}{\sqrt{n}}$, $L_{n}$  et $\mathbb{P}_{wig}$ la mesure associé à la distribution $f_{wig}(x)= \frac{\sqrt{(4\sigma^2 - x^2)_+}}{2\pi\sigma^2}$ on a:

\begin{equation}
	L_n\xrightarrow[n \to +\infty]{etr} \mathbb{P}_{wig}\nonumber
\end{equation}\\
\end{theorem}

Soit $V$ le profile de variance de $\frac{X}{\sqrt{n}}$. $\forall i = 1:n$ on a: 
\begin{align*} 
\sigma_{i \cdot}^2 &= \sum_{j=1}^{n}V_{ij}  \\
 		&= \frac{\sigma_{in}^2 + \sigma_{out}^2}{2}  \\
		&=\sigma^2
\end{align*}
Si on note $\rho(x)$ la densité spectrale de $\frac{X}{\sqrt{n}}$ on a;
\begin{equation}
	\rho(x) = \frac{\sqrt{(2(\sigma_{in}^2 + \sigma_{out}^2) - x^2)_+}}{\pi(\sigma_{in}^2 + \sigma_{out}^2)}
\end{equation}

Dans la suite de l'étude nous noterons B la matrice de modularité telle que 
\begin{align*} 
B :&= X + \frac{1}{2}(c_{in} - c_{out})\mathbf{uu}^T \\
\frac{B}{\sqrt{n}} &= \frac{X}{\sqrt{n}} + \frac{1}{2\sqrt{n}}(c_{in} - c_{out})\mathbf{uu}^T\\
\end{align*}
Soit v le vecteur propre de $\frac{B}{\sqrt{n}}$ de $\lambda_{max}$ et soit $\Gamma = \frac{X}{\sqrt{n}}$

\begin{align} 
\frac{B}{\sqrt{n}}\mathbf{v} &= \lambda_{max}\mathbf{v} \nonumber\\
(\Gamma - \lambda_{max}I)\mathbf{v} &= -\frac{1}{2\sqrt{n}}(c_{in} - c_{out})\mathbf{uu}^T \mathbf{v} \nonumber\\
 \mathbf{u^Tv} &= -\frac{1}{2\sqrt{n}}(c_{in} - c_{out})\mathbf{u^T}(\Gamma - \lambda_{max}I)^{-1}\mathbf{uu}^T \mathbf{v} \nonumber\\
 1 &= -\frac{1}{2\sqrt{n}}(c_{in} - c_{out})\mathbf{u^T}(\Gamma - \lambda_{max}I)^{-1}\mathbf{u} \label{eq:3}
\end{align}

% ------------------------------------------------- Théorème de Wigner isotrope -------------------------------------------------
\begin{theorem}[Théorème de Wigner isotrope]\label{th:2}
Soit $W \in M_{n}(\mathbb{R})$, telle que $W_{ij}$ sont des variables aléatoires réels, $\mathbb{E}(W_{ij}) = 0$, $\mathbb{E}(W_{ij}^2) < \infty$, $W_{ij} = W_{ji}$, W à un profile de variance V tel que $\forall i = 1:n , \; \sum_{j=1}^{n}V_{ij} = \sigma^2$ pour $\sigma \in \mathbb{R}$\\
Soit $Q(z)$ la résolvante de W
\begin{align*} 
Q(z) = (W - zI)^{-1}\\
\end{align*}
Soient $\mathbf{u}$, $\mathbf{v}$ des vecteurs déterministes tels que $\|\mathbf{u}\|, \|\mathbf{v}\| < \infty$.\\
Alors 
\begin{align*} 
\mathbf{u}^*Q(z)\mathbf{v} - \langle \mathbf{u}, \mathbf{v} \rangle g_{wig}^{\sigma^2} \xrightarrow[n \to +\infty]{} 0\\
\end{align*}
où $g_{wig}^{\sigma^2}$ est la transformé de Stieltjes de la loi de Wigner associé au paramètre $\sigma^2$\\
\end{theorem}

Reprenons l’équation \eqref{eq:3}, en appliquant le Théorème de Wigner isotrope et en s'assurant que tous les termes de droite convergent, nous avons:
\begin{align*}
\mathbf{u^T}(\Gamma - \lambda_{max}I)^{-1}\mathbf{u} \xrightarrow[n \to +\infty]{} g_{wig}^{\sigma^2}(\lambda_{max})
\end{align*}
or $g_{wig}^{\sigma^2}(\lambda_{max})$ satisfait l'équation suivante 
\begin{align}
	\sigma^2U^2+\lambda_{max}U+1=0 \implies U = \frac{- \lambda_{max} \pm \sqrt{(\lambda_{max}^2 - 4\sigma^2)}}{2\sigma^2}
\end{align}
Donc
\begin{align}
	\eqref{eq:3} &\Leftrightarrow1 = -\frac{1}{2\sqrt{n}}(c_{in} - c_{out}) g_{wig}^{\sigma^2}(\lambda_{max}) \nonumber\\
	&\Leftrightarrow 1 = -\frac{1}{2\sqrt{n}}(c_{in} - c_{out}) \frac{- \lambda_{max} - \sqrt{(\lambda_{max}^2 - 4\sigma^2)}}{2\sigma^2} \nonumber\\
	&\Leftrightarrow \lambda_{max} = \frac{(c_{in} - c_{out})}{2\sqrt{n}} + \sqrt{n}\frac{\sigma_{in}^2 + \sigma_{out}^2}{c_{in} - c_{out}} \label{z1}
\end{align}

de plus $\frac{1}{2\sqrt{n}}(c_{in} - c_{out}) = \mathcal{O}(\sqrt(n))$ et $\sqrt{n}\frac{\sigma_{in}^2 + \sigma_{out}^2}{c_{in} - c_{out}} =  \mathcal{O}(\frac{1}{\sqrt(n)})$\\
 
Comme $A = X + \frac{1}{2}(c_{in} + c_{out})\mathbf{11}^T + \frac{1}{2}(c_{in} - c_{out})\mathbf{uu}^T$ et $\langle\mathbf{u}, \mathbf{1}\rangle = 0 \; \|\mathbf{u}\|=\|\mathbf{v}\|=1$ on a
\begin{align}
	&\Leftrightarrow (\Gamma + \alpha\mathbf{11}^T + \beta \mathbf{uu}^T)\mathbf{v} = \lambda \mathbf{v}\nonumber\\
	&\Leftrightarrow (\Gamma - \lambda I)\mathbf{v} = -\alpha\mathbf{11}^T\mathbf{v} - \beta \mathbf{uu}^T\mathbf{v} \nonumber\\
	&\Leftrightarrow \mathbf{1^Tv} = -\alpha\mathbf{1^T} (\Gamma - \lambda I)^{-1}\mathbf{11}^T\mathbf{v} - \beta \mathbf{1^T} (\Gamma - \lambda I)^{-1}\mathbf{uu}^T\mathbf{v} \nonumber\\
	&\xrightarrow[n \to +\infty]{} 1 = -\alpha g_{wig}^{\sigma^2}(\lambda) \nonumber\\
	&\Leftrightarrow 1 = -\alpha  \frac{- \lambda - \sqrt{(\lambda^2 - 4\sigma^2)}}{2\sigma^2}\nonumber\\
	&\Leftrightarrow \lambda = \frac{(c_{in} + c_{out})}{2\sqrt{n}} + \sqrt{n}\frac{\sigma_{in}^2 + \sigma_{out}^2}{c_{in} + c_{out}} \label{z2}
\end{align} 

On a finalement une matrice A qui est la somme d'une matrice aléatoire X et de deux perturbations de rang 1.
De fait, la mesure spectrale de A à deux valeurs propres qui sortent du bulk, à savoir $\lambda_{max}$ et $\lambda$.
Par la suite nous noterons $z1 = \lambda_{max}$ et $z2 = \lambda$

\subsection{Interprétation des résultats obtenus}
\label{subsec:1.3}
On sait que si $p_{in} - p_{out} \le 0$  le graphe n'admet pas de structure de communauté.
De plus notre détection spectral nous dit que si la plus grande valeur propre sort du support de $\rho(z)$ alors il le graphe admet une structure de communauté.
La borne droite du support est $\lambda^+ = 2\sigma = \sqrt{2(\sigma_{in}^2 + \sigma_{out}^2)}$.

Dans la mesure où  $\lambda^+$ est positif ou nul, lorsque $p_{in} - p_{out} \in [0, p_{lim}]$ alors la méthode spectrale est incapable de conclure.\\
 
Nous cherchons à déterminer $p_{lim}$.
La condition limite naturelle est celle où la valeur propre maximale est égale au bord droit du support de la mesure spectrale de la matrice A.
On a alors 
\begin{align*}
	&\Leftrightarrow \lambda^+ = \lambda_{max}\\
	&\Leftrightarrow \sqrt{2(\sigma_{in}^2 + \sigma_{out}^2)} = \frac{(c_{in} - c_{out})}{2\sqrt{n}} + \sqrt{n}\frac{\sigma_{in}^2 + \sigma_{out}^2}{c_{in} - c_{out}}\\
	&\Leftrightarrow \sqrt{2S} = \alpha + \beta S\\
	&\Leftrightarrow 2S = \alpha^2 + 2\alpha \beta S +\beta^2 S^2\\
	&\Leftrightarrow 0 = \beta^2 S^2 + 2(\alpha \beta - 1)S+ \alpha^2 \\
	&\text{après résolution de l'équation on obtient une unique solution}\\
	&\Leftrightarrow p_{in} - p_{out} = \frac{\sqrt{2(\sigma_{in}^2 + \sigma{out}^2)}}{\sqrt{n}}  \\
\end{align*}
Donc
\begin{equation}
	p_{lim} = \frac{\sqrt{2(\sigma_{in}^2 + \sigma_{out}^2)}}{\sqrt{n}}= \frac{2\sigma}{\sqrt{n}}  \\
\end{equation}

\paragraph{}\label{rq:ngrand}
D'après ce modèle, plus on a de noeuds dans le graphe, plus on a de l'information, et donc moins on a de chance de tomber sur cet intervalle d’indécidabilité.\\

Ci-dessous un tableau comparatif entre les résultats obtenus et ceux de l'article.
L'essence de la divergence intervient lorsque qu'il est défini que $\mathbb{V}(X_{ij}) = \frac{(c_{in} + c_{out})}{2n}$.
\underline{À gauche}: les résultats de l'article original; \underline{À droite}: les résultats obtenus ci-dessus:

\begin{align*}
	\rho (z)&: \frac{n}{\pi}\frac{\sqrt{(2(c_{in} + c_{out}) - x^2)_+}}{\pi(c_{in} + c_{out})} &\;& \frac{\sqrt{(2(\sigma_{in}^2 + \sigma_{out}^2) - x^2)_+}}{\pi(\sigma_{in}^2 + \sigma_{out}^2)}\\
	\sigma^2&: \frac{c_{in} + c_{out}}{2n} &\;& \frac{\sigma_{in}^2 + \sigma_{out}^2}{2} \\
	z1&: \frac{c_{in}-c_{out}}{2} + \frac{c_{in}+c_{out}}{c_{in}-c_{out}} &\;& \frac{c_{in}-c_{out}}{2\sqrt{n}} + \sqrt{n}\frac{\sigma_{in}^2+\sigma_{out}^2}{c_{in}-c_{out}}\\
	z2&: \frac{c_{in}+c_{out}}{2} + 1 &\;& \frac{c_{in}+c_{out}}{2\sqrt{n}} + \sqrt{n}\frac{\sigma_{in}^2+\sigma_{out}^2}{c_{in}+c_{out}}\\
	p_{lim}&: \frac{\sqrt{2(c_{in} - c_{out})}}{\sqrt{n}}&\;& \frac{\sqrt{2(\sigma_{in}^2 + \sigma_{out}^2)}}{\sqrt{n}}\\
\end{align*}


