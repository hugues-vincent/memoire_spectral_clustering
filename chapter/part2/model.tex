% \part{partie}
% \chapter{chapitre}
% \section{section}
% \subsection{sous-section}
% \subsubsection{sous-sous-section}
% \paragraph{paragraphe}
% \subparagraph{sous-paragraphe}
\section{Théorie}
\subsection{Contexte: Stochastic Block Model à 2 communautés}
Le but de ce papier est d'expliquer en détail la méthode de détection de communauté via la théorie spectrale de l'article de RR. Nadakuditi et M. E. J. Newmann.
C'est un article qui décrit les limites d'un modèle spectral dans un cadre spécifique à deux communautés.

Nous allons nous placer dans le contexte d'un Stochastic Block Model (SBM) à deux communautés (i.e \textbf{q}=2).
C'est un graphe \textbf{G} non orienté à \textbf{n} nœuds dont chaque arête entre deux nœuds suit une loi de Bernoulli de paramètre $p_{in}$ si les nœuds appartiennent à la même communauté et $p_{out}$ si les nœuds ne sont pas dans la même communauté.  

Nous noterons \textbf{A} la matrice d'adjacence du graphe \textbf{G}.
Elle est symétrique de par le fait que le graphe soit non orienté.
Nous supposerons d'ailleurs, que ses éléments sont rangés dans l'ordre de leur communauté.
Dans notre cas avec \textbf{q}=2, les $\mathbf{n}/2$ premières lignes correspondent aux noeuds de la communauté 1, et les $\mathbf{n}/2$ dernières la communauté 2.
Même chose pour les colonnes, par symétrie de \textbf{A}.\\
Cette disposition des éléments ne change pas le résultat final de l'analayse.
En effet, on sait que toutes les matrices congruentes représentes la même forme bilinéaire dans des bases différentes. 
Or le but de la procédure qui va suivre va être d'analyser la distribution des valeurs propres de notre matrice.
Par conséquent ranger les colonnes d'une matrice selon un ordre arbitraire correspond à la même forme bilinéaire et donc aux mêmes valeurs propres.\\

Chaque élément de la matrice \textbf{A} est simulé par une loi de Bernoulli avec: 
\begin{equation}\label{rq:probability}
 A_{ij} \sim \left\{
  \begin{array}{lr}
    B(p_{in}) & : (i,j < \frac{n}{2}) \; ou \; (i,j \ge \frac{n}{2}) \\
    B(p_{out}) & : else \; where
  \end{array}
\right.\nonumber
\end{equation}
\begin{equation} 
A_{ij} = A_{ji}\nonumber
\end{equation}


\subsection{Analyse spectrale de la matrice d'adjacence \textbf{A}}\label{ch:Analyse spectrale de la matrice d'adjacence}
L'idée générale de l'analyse spectrale qui va suivre est de nous ramener à un régime spectral de grande matrices aléatoires connu. 
Dans notre cas, nous verrons que le régime associé à notre matrice d'adjacence (SBM $\textbf{q}=2$) est celui du théorème de \textit{Wigner} avec perturbation de rang fini.
La trame sera la suivante:
\begin{itemize}
 	\item[1-] réécriture de la matrice $A = \langle A \rangle + X$;
 	\item[2-] étude de la mesure spectrale de X;
 	\item[3-] étude de la mesure spectrale de B où $B = X + P_1$;
 	\item[4-] étude de la mesure spectrale de $A = B + P_2 = X + P_1 + P_2$.
 \end{itemize} 
où $P_1$, $P_2$ sont des perturbations de rang 1 et $\langle A \rangle$ correspond à la moyenne de A du SBM.\\
% ------------------------------------------------- equation (1) -------------------------------------------------
\subsubsection*{1- Équation de $\langle A \rangle$}
En partant de $A$, on définit $\langle A \rangle$ comme la matrice dont les entrées $\langle A \rangle _{ij} = \mathbb{E}(A_{ij})$
Soit
\begin{align*}
	\langle A \rangle 
	&=
	\begin{bmatrix}
		p_{in} & p_{out}\\
		p_{out} & p_{in}\\
	\end{bmatrix} \otimes \mathbf{1}_{\frac{n}{2}}\mathbf{1}_{\frac{n}{2}}^T \times \frac{n}{2}\\
	&=
	\begin{bmatrix}
		c_{in} & c_{out}\\
		c_{out} & c_{in}\\
	\end{bmatrix} \otimes \mathbf{1}_{\frac{n}{2}}\mathbf{1}_{\frac{n}{2}}^T \times \frac{1}{2}\\
	&=\left(\frac{1}{2} \times
	\begin{bmatrix}
		c_{in} + c_{out} & c_{in} + c_{out}\\
		c_{in} + c_{out} & c_{in} + c_{out}\\
	\end{bmatrix} 
	+ \frac{1}{2} \times
	\begin{bmatrix}
		c_{in} - c_{out} & -c_{in} + c_{out}\\
		-c_{in} + c_{out} & c_{in} - c_{out}\\
	\end{bmatrix}
	\right) \otimes \mathbf{1}_{\frac{n}{2}}\mathbf{1}_{\frac{n}{2}}^T \times \frac{1}{2}\\
	&=\left(\frac{1}{2} (c_{in} + c_{out})\times \mathbf{1}_2\mathbf{1}_2^T
	+ \frac{1}{2} (c_{in} - c_{out}) \times \mathbf{u}_2\mathbf{u}_2^T
	\right) \otimes \mathbf{1}_{\frac{n}{2}}\mathbf{1}_{\frac{n}{2}}^T\\
	&= \frac{1}{2}(c_{in} + c_{out})\mathbf{1}_n\mathbf{1}_n^T + \frac{1}{2}(c_{in} - c_{out})\mathbf{u}_n\mathbf{u}_n^T \numberthis \label{eq:1}
\end{align*}
Avec
\begin{align*}
c_{in} &= np_{int} \\
c_{out} &= np_{out}\\
\mathbf{1}_n &= (\underbrace{1,\ldots,1}_{n\text{-times}})/\sqrt{n}\\
\mathbf{u}_n &= (\underbrace{1,\ldots,1}_{\frac{n}{2}\text{-times}}, \underbrace{-1,\ldots,1}_{\frac{n}{2}\text{-times}})/\sqrt{n}\\
\langle\mathbf{1_n}|\mathbf{u_n}\rangle &= 0
\end{align*}


À présent \textbf{A} peut être écrite sous la forme $A = \langle A \rangle + X$.
La matrice X est interprétable comme la déviation entre la matrice d'adjacence du graphe et sa moyenne.
La matrice X est par définition une matrice aléatoire symétrique à entrées indépendantes et de moyenne 0.
Essayons d'analyser sa mesure spectrale.
On a 

\begin{equation} \label{eq: X}
X = A - \langle A \rangle
\end{equation}
\begin{equation}
	X_{ij}  = \left\{
	\begin{array}{lr}
		B_{ij}(p_{in}) - p_{in} & : (i,j < \frac{n}{2}) \; ou \; (i,j \ge \frac{n}{2}) \\
		B_{ij}(p_{out}) - p_{out} & : else \; where
	\end{array}
\right.\nonumber
\end{equation}
Où $B_{ij}(p) \sim B(p)$, $B(p)$ loi de Bernoulli de paramètre p et $B_{ij} = B_{ji}$\\


% ------------------------------------------------- 2- trouver X  -------------------------------------------------
\subsubsection*{2- Recherche de la mesure spectrale de $\frac{X}{\sqrt{n}}$}
Nous aimerions modifier la forme des entrées $X_{ij}$ en $\sigma_{ij} Z_{ij}$, où $Z_{ij}$ est une variable aléatoire centrée réduite, afin de nous ramener à des théorèmes connus.

Pour $(i,j < \frac{n}{2}) \; ou \; (i,j \ge \frac{n}{2}) $ on a:
\begin{align*}
\mathbb{E}(X_{ij}) &= \mathbb{E}(B(p_{in}))- p_{in} = 0\\
\sigma_{in}^2 &= \mathbb{V}(X_{ij}) \\ 
			  &= \mathbb{V}(B(p_{in})) \\
			  &= p_{in} (1 - p_{in})
\end{align*}
même raisonnement avec $p_{out}$ 
\begin{align*}
\sigma_{out}^2 =  p_{out} (1 - p_{out})
\end{align*}
finalement on obtient 
\begin{equation}
	X_{ij} \sim \left\{
	\begin{array}{lr}
		\sigma_{in} Z_{ij} & : (i,j < \frac{n}{2}) \; ou \; (i,j \ge \frac{n}{2}) \\
		\sigma_{out} Z_{ij} & : else \; where
	\end{array}
\right.\nonumber
\end{equation}
Où $Z_{ij} = \frac{B(p) - p}{\sqrt{p(1-p)}} \;\;avec \; p = p_{in} \; ou \; p_{out}$\\

% ------------------------------------------------- théorème 1 -------------------------------------------------
Le théorème de Wigner ne fonctionne que pour les matrices à entrées iid. 
Il existe un théorème lorsque le profil de variance de la matrice aléatoire étudié est stochastique.
\begin{theorem}\label{th:1}
Soit $W \in M_{n}(\mathbb{R})$, $W_{ij}$ sont des variables aléatoires réelles\\
On suppose que les $(W_{ij})_{i \leq j}$ sont indépendantes telles que $\mathbb{E}(W_{ij}) = 0$, $\sigma_{ij}^2 = \mathbb{E}(W_{ij}^2) < \infty$, $W_{ij} = W_{ji}$\\
On appelle profil de variance la matrice symétrique
\begin{align*}
	\tilde V_n = (\sigma_{ij}^2)_{1 \leq i,j \leq n}
\end{align*}
et profil de variance normalisé 
\begin{align*}
	V_n = \left(\frac{\sigma_{ij}^2}{n}\right)_{1 \leq i,j \leq n}
\end{align*}
On suppose que $V_n$ est stochastique: $\forall i = 1:n , \; \sum_{j=1}^{n}V_{ij} = \sigma^2$\\
Alors la mesure spectrale $L_{n}$ de $\frac{W}{\sqrt{n}}$ vérifie

\begin{equation}
	L_n\xrightarrow[n \to +\infty]{etr} \mathbb{P}_{wig}\nonumber \; p.s
\end{equation}\\
où $\mathbb{P}_{wig}$ est la loi de Wigner de densité $f_{wig}(x)= \frac{\sqrt{(4\sigma^2 - x^2)_+}}{2\pi\sigma^2}$
\end{theorem}

Soit $V$ le profil de variance de $\frac{X}{\sqrt{n}}$. $\forall i = 1:n$ on a: 
\begin{align*} 
\sigma_{i \cdot}^2 &= \sum_{j=1}^{n}V_{ij}  \\
 		&= \boxed{\frac{\sigma_{in}^2 + \sigma_{out}^2}{2} = \sigma^2}
\end{align*}
Si on note $\rho(x)$ la densité spectrale de $\frac{X}{\sqrt{n}}$ on a;
\begin{equation}
	\rho(x) = \frac{\sqrt{(2(\sigma_{in}^2 + \sigma_{out}^2) - x^2)_+}}{\pi(\sigma_{in}^2 + \sigma_{out}^2)}
\end{equation}

% ------------------------------------------------- 3- étude de B  -------------------------------------------------
\subsubsection*{3- Étude de la mesure spectrale de $\frac{X}{\sqrt{n}}$ et recherche de ces valeurs propres maximales}
Nous venons de trouver la densité spectrale de $\frac{X}{\sqrt{n}}$.
Nous voulons à présent étudier ces valeurs propres.
Pour ce faire nous allons séparer l'équation $\frac{X}{\sqrt{n}} = \frac{1}{\sqrt{n}}(A - \langle A \rangle)$ en deux parties, à savoir $\frac{X}{\sqrt{n}} = \frac{1}{\sqrt{n}}(B \;+\; \frac{1}{2}(c_{in} + c_{out})\mathbf{11}^T)$\\
Dans la suite de l'étude nous noterons B la matrice de modularité telle que 
\begin{align*} 
B :&= X + \frac{1}{2}(c_{in} - c_{out})\mathbf{uu}^T \\
\frac{B}{\sqrt{n}} &= \frac{X}{\sqrt{n}} + \frac{1}{2\sqrt{n}}(c_{in} - c_{out})\mathbf{uu}^T\\
\end{align*}
Le raisonnement qui va suivre est une heuristique. En effet, pour compléter rigoureusement la preuve qui va suivre, il faudrait vérifier la convergence du terme $\frac{B}{\sqrt{n}}$ en entier.\\

Soit v le vecteur propre de $\frac{B}{\sqrt{n}}$ associé à $\lambda_{max}$ et soit $\Gamma = \frac{X}{\sqrt{n}}$

\begin{align} 
\frac{B}{\sqrt{n}}\mathbf{v} &= \lambda_{max}\mathbf{v} \nonumber\\
(\Gamma - \lambda_{max}I)\mathbf{v} &= -\frac{1}{2\sqrt{n}}(c_{in} - c_{out})\mathbf{uu}^T \mathbf{v} \nonumber\\
 \mathbf{u^Tv} &= -\frac{1}{2\sqrt{n}}(c_{in} - c_{out})\mathbf{u^T}(\Gamma - \lambda_{max}I)^{-1}\mathbf{uu}^T \mathbf{v} \nonumber\\
 1 &= -\frac{1}{2\sqrt{n}}(c_{in} - c_{out})\mathbf{u^T}(\Gamma - \lambda_{max}I)^{-1}\mathbf{u} \label{eq:3}
\end{align}

% ------------------------------------------------- Théorème de Wigner isotrope -------------------------------------------------
\begin{theorem}[Théorème de Wigner isotrope]\label{th:2}

Soit $W \in M_{n}(\mathbb{R})$, telle que $W_{ij}$ sont des variables aléatoires réels, $\mathbb{E}(W_{ij}) = 0$, $\mathbb{E}(W_{ij}^2) < \infty$, $W_{ij} = W_{ji}$, W à un profil de variance V tel que $\forall i = 1:n , \; \sum_{j=1}^{n}V_{ij} = \sigma^2$ pour $\sigma \in \mathbb{R}$\\
Soit $Q(z)$ la résolvante de W
\begin{align*} 
Q(z) = (W - zI)^{-1}\\
\end{align*}
Soient $\mathbf{u}$, $\mathbf{v}$ des vecteurs déterministes tels que $\|\mathbf{u}\|, \|\mathbf{v}\| < \infty$.\\
Alors 
\begin{align*} 
\mathbf{u}^*Q(z)\mathbf{v} - \langle \mathbf{u}, \mathbf{v} \rangle g_{wig}^{\sigma^2}(z) \xrightarrow[n \to +\infty]{} 0\\
\end{align*}
où $g_{wig}^{\sigma^2}$ est la transformé de Stieltjes de la loi de Wigner de paramètre $\sigma^2$ qui satisfait l'équation
\begin{equation}
	\sigma^2g_{wig}^{\sigma^2}(z)^2+z g_{wig}^{\sigma^2}(z)+1=0
\end{equation}\\
\end{theorem}

Reprenons l’équation \eqref{eq:3}, en appliquant le Théorème de Wigner isotrope et en s'assurant que tous les termes de droite convergent, nous avons:
\begin{align*}
\mathbf{u^T}(\Gamma - \lambda_{max}I)^{-1}\mathbf{u} \xrightarrow[n \to +\infty]{} g_{wig}^{\sigma^2}(\lambda_{max})
\end{align*}
or $g_{wig}^{\sigma^2}(\lambda_{max})$ satisfait l'équation suivante 
\begin{align}
	\sigma^2g_{wig}^{\sigma^2}(\lambda_{max})^2+\lambda_{max}g_{wig}^{\sigma^2}(\lambda_{max})+1=0 \implies g_{wig}^{\sigma^2}(\lambda_{max}) = \frac{- \lambda_{max} \pm \sqrt{(\lambda_{max}^2 - 4\sigma^2)}}{2\sigma^2}
\end{align}
Donc
\begin{align}
	\eqref{eq:3} &\Leftrightarrow1 = -\frac{1}{2\sqrt{n}}(c_{in} - c_{out}) g_{wig}^{\sigma^2}(\lambda_{max}) \nonumber\\
	&\Leftrightarrow 1 = -\frac{1}{2\sqrt{n}}(c_{in} - c_{out}) \frac{- \lambda_{max} - \sqrt{(\lambda_{max}^2 - 4\sigma^2)}}{2\sigma^2} \nonumber\\
	&\Leftrightarrow \boxed{\lambda_{max}=\frac{(c_{in} - c_{out})}{2\sqrt{n}} + \sqrt{n}\frac{\sigma_{in}^2 + \sigma_{out}^2}{c_{in} - c_{out}}} \label{z_1}
\end{align}

de plus $\frac{1}{2\sqrt{n}}(c_{in} - c_{out}) = \mathcal{O}(\sqrt{n})$ et $\sqrt{n}\frac{\sigma_{in}^2 + \sigma_{out}^2}{c_{in} - c_{out}} =  \mathcal{O}\left(\frac{1}{\sqrt{n}}\right)$\\
 
Comme $A = X + \frac{1}{2}(c_{in} + c_{out})\mathbf{11}^T + \frac{1}{2}(c_{in} - c_{out})\mathbf{uu}^T$ et $\langle\mathbf{u}, \mathbf{1}\rangle = 0 \; \|\mathbf{u}\|=\|\mathbf{v}\|=1$ on a
\begin{align}
	&\Leftrightarrow (\Gamma + \alpha\mathbf{11}^T + \beta \mathbf{uu}^T)\mathbf{v} = \lambda \mathbf{v}\nonumber\\
	&\Leftrightarrow (\Gamma - \lambda I)\mathbf{v} = -\alpha\mathbf{11}^T\mathbf{v} - \beta \mathbf{uu}^T\mathbf{v} \nonumber\\
	&\Leftrightarrow \mathbf{1^Tv} = -\alpha\mathbf{1^T} (\Gamma - \lambda I)^{-1}\mathbf{11}^T\mathbf{v} - \beta \mathbf{1^T} (\Gamma - \lambda I)^{-1}\mathbf{uu}^T\mathbf{v} \nonumber\\
	&\xrightarrow[n \to +\infty]{} 1 = -\alpha g_{wig}^{\sigma^2}(\lambda) \nonumber\\
	&\Leftrightarrow 1 = -\alpha  \frac{- \lambda - \sqrt{(\lambda^2 - 4\sigma^2)}}{2\sigma^2}\nonumber\\
	&\Leftrightarrow \boxed{\lambda = \frac{(c_{in} + c_{out})}{2\sqrt{n}} + \sqrt{n}\frac{\sigma_{in}^2 + \sigma_{out}^2}{c_{in} + c_{out}}} \label{z_2}
\end{align} 

On a finalement une matrice A qui est la somme d'une matrice aléatoire X et de deux perturbations de rang 1.
De fait, la mesure spectrale de A à deux valeurs propres qui sortent du support de la distribution de Wigner, à savoir $\lambda_{max}$ et $\lambda$.
Par la suite nous noterons $z_1 = \lambda_{max}$ et $z_2 = \lambda$, et nous appellerons ``bulk'' le support de la mesure spectrale $\rho(z)$.

\subsection{Interprétation des résultats obtenus}
\label{subsec:1.3}
Si les 2 plus petites valeurs propres sont inférieures au bord gauche du bulk (ici $\lambda^- = -2\sigma$) alors le graphe admet une structure de communauté ``disassortative''.
Si les 2 plus grandes valeurs propres sont supérieures au bord droit du bulk (ici $\lambda^+ = 2\sigma$) alors le graphe admet une structure de communauté ``assortative''.
Si $0$ ou $1$ valeur propre sort du bulk alors la méthode spectrale ne peut rien conclure sur la structure de communauté du graphe G.\\

Il est important de remarquer que $z_2$ est toujours supérieure au bord droit du bulk, indépendamment des valeurs de $p_{in}$ et $p_{out}$.
Par conséquent, c'est $z_1$ qui nous indique si oui ou non il y a une structure de communauté dans le graphe.\\

Nous cherchons à déterminer $p_{lim} = p_{in} - p_{out}$, qui est la condition limite supérieure sur les paramètres du SBM pour que l'algorithme puisse détecter la structure de communauté ``assortative'' du graphe G.
Dans la mesure où  $\lambda^+$ est positif ou nul, lorsque $p_{in} - p_{out} \in [0, p_{lim}]$ alors la méthode spectrale est incapable de conclure sur la structure ``assortative''.\\
 
La condition limite naturelle est celle où la valeur propre maximale est égale au bord droit du support de la mesure spectrale de la matrice A.
À partir de cette condition nous allons essayer de retrouver $p_{lim}$.\\
On a alors 
\begin{align*}
	&\Leftrightarrow \lambda^+ = \lambda_{max}\\
	&\Leftrightarrow \sqrt{2(\sigma_{in}^2 + \sigma_{out}^2)} = \frac{(c_{in} - c_{out})}{2\sqrt{n}} + \sqrt{n}\frac{\sigma_{in}^2 + \sigma_{out}^2}{c_{in} - c_{out}}\\
	&\Leftrightarrow \sqrt{2S} = \alpha + \beta S &\; avec  \; S = \sigma_{in}^2 + \sigma_{out}^2,\;\alpha=\frac{(c_{in} - c_{out})}{2\sqrt{n}}, \; \beta=  \frac{\sqrt{n}}{c_{in} - c_{out}}\\
	&\Leftrightarrow 2S = \alpha^2 + 2\alpha \beta S +\beta^2 S^2\\
	&\Leftrightarrow 0 = \beta^2 S^2 + 2(\alpha \beta - 1)S+ \alpha^2 \\
	&\Leftrightarrow p_{in} - p_{out} = \frac{\sqrt{2(\sigma_{in}^2 + \sigma_{out}^2)}}{\sqrt{n}}  \\
\end{align*}
Donc
\begin{equation}
	\boxed{p_{lim} = \frac{\sqrt{2(\sigma_{in}^2 + \sigma_{out}^2)}}{\sqrt{n}}= \frac{2\sigma}{\sqrt{n}} = \mathcal{O}\left(\frac{1}{\sqrt{n}}\right)}\\
\end{equation}

\paragraph{}\label{rq:ngrand}
D'après ce modèle, plus on a de noeuds dans le graphe, plus on a de l'information, et donc moins on a de chance de tomber sur cet intervalle d’indécidabilité.\\

\subsection{Bilan}
Ci-dessous un tableau comparatif entre les résultats obtenus et ceux de l'article \cite{raj_rao}.
L'essence de la divergence intervient lorsque qu'il est défini que $\mathbb{V}(X_{ij}) = \frac{(c_{in} + c_{out})}{2n}$.
Nous avons normalisé les équations de l'article original par $\frac{1}{\sqrt{n}}$ afin de pouvoir les comparer avec nos résultats.\\
\underline{Rappel}: $\sigma_{in}^2=p_{in}(1-p_{in})$ ; $\sigma_{out}^2=p_{out}(1-p_{out})$ ; $c_{in} = np_{in}$ ; $c_{out} = p_{out}$

\renewcommand{\arraystretch}{2}
\begin{table}[h] 
	\label{tab:bilan}
	\centering
    \begin{tabular}{|l|l|l|}
    \hline
      &  Résultats de l'article  &  Résultats obtenus \\ \hline
    $\rho (z)$  &  $\frac{1}{\pi\sqrt{n}}\frac{\sqrt{(2(c_{in} + c_{out}) - x^2)_+}}{(c_{in} + c_{out})}$&  $\frac{\sqrt{(2(\sigma_{in}^2 + \sigma_{out}^2) - x^2)_+}}{\pi(\sigma_{in}^2 + \sigma_{out}^2)}$\\ \hline
    $z_1$&  $\frac{c_{in}-c_{out}}{2\sqrt{n}} + \sqrt{n}\frac{c_{in}+c_{out}}{c_{in}-c_{out}}$ &  $\frac{c_{in}-c_{out}}{2\sqrt{n}} + \sqrt{n}\frac{\sigma_{in}^2+\sigma_{out}^2}{c_{in}-c_{out}}$\\ \hline
    $z_2$&  $\frac{c_{in}+c_{out}}{2\sqrt{n}} + \sqrt{n}$ &  $\frac{c_{in}+c_{out}}{2\sqrt{n}} + \sqrt{n}\frac{\sigma_{in}^2+\sigma_{out}^2}{c_{in}+c_{out}}$\\ \hline
    $p_{lim}$&  $\frac{\sqrt{2(c_{in} - c_{out})}}{n}$ &  $\frac{\sqrt{2(\sigma_{in}^2 + \sigma_{out}^2)}}{\sqrt{n}}$\\ \hline
    \end{tabular}
\end{table}

Les résultats quantitatifs empiriques que nous avons obtenu sont différents de ceux de l'article de référence.
Au contraire, les simulations corroborent les formules trouvées ci-dessus.
Nous le verrons plus précisément dans la section suivante.   
